{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cabc458",
   "metadata": {},
   "source": [
    "<img src=\"img/prefect-logo.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f59afe9",
   "metadata": {},
   "source": [
    "# Part 1: Dipping your toes into Prefect\n",
    "Data workflow orchestrators are used to coordinate, monitor and observe data movement. Features that make data-pipelines fault-tolerant include:\n",
    "- scheduling and triggering jobs\n",
    "- adding retries\n",
    "- dependency and state depedencies ('if the previous job failed')\n",
    "- caching expensive tasks\n",
    "- deploying flows to different environment \n",
    "- visibility into execution state of all jobs in your workflows\n",
    "\n",
    "Stop safeguarding against failure! Instead, enjoy a single pane of glass for monitoring your code. \n",
    "\n",
    "Let's gain visibility into our Python scripts with Prefect. All we have to do for observability, scheduling and more is to add a single `@flow` decorator (and optionally `@task` decorators). After that, we'll also create a deployment, view it in the UI, add a schedule, and watch our code run in the Prefect UI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbf8920",
   "metadata": {},
   "source": [
    "## Before beginnning\n",
    "Take a look at `prefect_ml.py`. Note that the only difference from regular Python code is the addition of the Prefect `@task` and `@flow` decorators (flows are made up of tasks).\n",
    "\n",
    "## What we will do in this demo\n",
    "1. Installation of dependencies\n",
    "2. We will first import a flow from prefect_ml.py.\n",
    "3. We will run that flow locally.\n",
    "4. We will then view our flow run in the UI. \n",
    "5. We will deploy our code so that we don't need to run it locally anymore.\n",
    "6. We will add a schedule to our code. \n",
    "7. We will start a local agent that can execute our code on our schedule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e50dd",
   "metadata": {},
   "source": [
    "## First, we'll install Prefect and some other dependencies our script has to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df94a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install prefect==2.3.1 prefect-dask sklearn pandas\n",
    "# The magic capture cmd simply suppresses the install output, which is lengthy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851fc8f5",
   "metadata": {},
   "source": [
    "## Import code from prefect_ml.py\n",
    "We will import the flow called `my_first_ml_flow` from `prefect_ml.py`. The function has a `@flow` decorator on it, thus making it a `flow`. We will see what is so great about that in just moments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19ecc749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported my_first_ml_flow\n"
     ]
    }
   ],
   "source": [
    "# Importing my_first_ml_flow function w/ @flow decorator\n",
    "from prefect_ml import my_first_ml_flow\n",
    "print(\"Imported my_first_ml_flow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25044d50",
   "metadata": {},
   "source": [
    "## Run your flow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f571e734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:43:16.896 | INFO    | prefect.engine - Created flow run 'practical-peacock' for flow 'my-first-ml-flow'\n",
      "09:43:16.897 | INFO    | prefect.task_runner.dask - Creating a new Dask cluster with `distributed.deploy.local.LocalCluster`\n",
      "09:43:17.532 | INFO    | prefect.task_runner.dask - The Dask dashboard is available at http://127.0.0.1:8787/status\n",
      "09:43:17.774 | INFO    | Flow run 'practical-peacock' - Created task run 'create-data-2fa802fa-0' for task 'create-data'\n",
      "09:43:17.774 | INFO    | Flow run 'practical-peacock' - Executing 'create-data-2fa802fa-0' immediately...\n",
      "09:43:17.821 | INFO    | Task run 'create-data-2fa802fa-0' - Finished in state Completed()\n",
      "09:43:17.836 | INFO    | Flow run 'practical-peacock' - Created task run 'get-models-fa4a86ce-0' for task 'get-models'\n",
      "09:43:17.836 | INFO    | Flow run 'practical-peacock' - Executing 'get-models-fa4a86ce-0' immediately...\n",
      "09:43:17.881 | INFO    | Task run 'get-models-fa4a86ce-0' - Finished in state Completed()\n",
      "09:43:17.897 | INFO    | Flow run 'practical-peacock' - Created task run 'train-models-2eff1204-0' for task 'train-models'\n",
      "09:43:17.897 | INFO    | Flow run 'practical-peacock' - Executing 'train-models-2eff1204-0' immediately...\n",
      "09:43:17.942 | INFO    | Task run 'train-models-2eff1204-0' - Finished in state Completed()\n",
      "09:43:17.957 | INFO    | Flow run 'practical-peacock' - Created task run 'train-models-2eff1204-1' for task 'train-models'\n",
      "09:43:17.958 | INFO    | Flow run 'practical-peacock' - Executing 'train-models-2eff1204-1' immediately...\n",
      "09:43:17.999 | INFO    | Task run 'train-models-2eff1204-1' - Finished in state Completed()\n",
      "09:43:18.015 | INFO    | Flow run 'practical-peacock' - Created task run 'train-models-2eff1204-2' for task 'train-models'\n",
      "09:43:18.016 | INFO    | Flow run 'practical-peacock' - Executing 'train-models-2eff1204-2' immediately...\n",
      "09:43:18.048 | INFO    | Task run 'train-models-2eff1204-2' - Finished in state Completed()\n",
      "09:43:18.063 | INFO    | Flow run 'practical-peacock' - Created task run 'train-models-2eff1204-3' for task 'train-models'\n",
      "09:43:18.064 | INFO    | Flow run 'practical-peacock' - Executing 'train-models-2eff1204-3' immediately...\n",
      "09:43:18.105 | INFO    | Task run 'train-models-2eff1204-3' - Finished in state Completed()\n",
      "09:43:18.120 | INFO    | Flow run 'practical-peacock' - Created task run 'train-models-2eff1204-4' for task 'train-models'\n",
      "09:43:18.121 | INFO    | Flow run 'practical-peacock' - Executing 'train-models-2eff1204-4' immediately...\n",
      "09:43:18.298 | INFO    | Task run 'train-models-2eff1204-4' - Finished in state Completed()\n",
      "09:43:18.314 | INFO    | Flow run 'practical-peacock' - Created task run 'train-models-2eff1204-5' for task 'train-models'\n",
      "09:43:18.314 | INFO    | Flow run 'practical-peacock' - Executing 'train-models-2eff1204-5' immediately...\n",
      "09:43:18.415 | INFO    | Task run 'train-models-2eff1204-5' - Finished in state Completed()\n",
      "09:43:18.431 | INFO    | Flow run 'practical-peacock' - Created task run 'get_results-5c756677-0' for task 'get_results'\n",
      "09:43:18.431 | INFO    | Flow run 'practical-peacock' - Executing 'get_results-5c756677-0' immediately...\n",
      "09:43:18.466 | INFO    | Task run 'get_results-5c756677-0' - Finished in state Completed()\n",
      "2022-09-06 09:43:18,492 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:64477'.\n",
      "2022-09-06 09:43:18,493 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:64477'. Shutting down.\n",
      "09:43:18.590 | INFO    | Flow run 'practical-peacock' - Finished in state Completed()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.752809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.691011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.713483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>0.651685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.792135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                                             params  \\\n",
       "0      LogisticRegression  {'C': 1.0, 'class_weight': None, 'dual': False...   \n",
       "1    KNeighborsClassifier  {'algorithm': 'auto', 'leaf_size': 30, 'metric...   \n",
       "2  DecisionTreeClassifier  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "3                     SVC  {'C': 1.0, 'break_ties': False, 'cache_size': ...   \n",
       "4  RandomForestClassifier  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...   \n",
       "\n",
       "   accuracy  \n",
       "0  0.752809  \n",
       "1  0.691011  \n",
       "2  0.713483  \n",
       "3  0.651685  \n",
       "4  0.792135  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_first_ml_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e39f9",
   "metadata": {},
   "source": [
    "As we can see, info logs were generated about this flow run. We also have a flow run name! For example, your flow run name might be 'practical peacock`. Each flow run name is unique. But now let's kick thing up a notch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e428a5e",
   "metadata": {},
   "source": [
    "## View your flow run in the UI\n",
    "1. Copy this command: `prefect orion start`. This command will allow you to start an Orion server, enabling you to view your flow!\n",
    "2. Visit the `Jupyter Home Page` tab that is already open in your browser. Click \"New\" in the right-hand corner and choose \"Terminal\". Paste the command you copied :)\n",
    "2. Visit http://127.0.0.1:4200. In the Flow Runs tab, you should see your flow run name (e.g. 'practical peacock'), which you can click on view its logs, task runs, parameters, execution state, and more.\n",
    "\n",
    "<img src=\"img/viewing-flow-run.png\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3770e7",
   "metadata": {},
   "source": [
    "# Part 2: Create a deployment in one command\n",
    "Now that you have run a flow and viewed it in the UI, let's create a deployment. Deploying your flow means you no longer need to call the function, flow or .py file locally to run your code. With a single command, any script you write in Python can be executed regularly while enabling you to be notified of failures and observe the state of your jobs at all times.\n",
    "\n",
    "Run the following command, which will build and apply a deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7c942d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found flow 'my-first-ml-flow'\n",
      "Deployment YAML created at \n",
      "'/Users/bean/Documents/prefect-in-jupyter-notebook/my_first_ml_flow-deployment.y\n",
      "aml'.\n",
      "Deployment 'my-first-ml-flow/ML Flow Deployment' successfully created with id \n",
      "'3490b13d-8a13-4d85-b490-b7de3bcdf649'.\n",
      "\n",
      "To execute flow runs from this deployment, start an agent that pulls work from \n",
      "the the 'default' work queue:\n",
      "$ prefect agent start -q 'default'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "prefect deployment build prefect_ml:my_first_ml_flow --name \"ML Flow Deployment\" --apply --skip-upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ca00b1",
   "metadata": {},
   "source": [
    "We don't need to worry about starting an agent quite yet. For now, let's head on over to the UI to view our newly created deployment!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d78e884",
   "metadata": {},
   "source": [
    "## Add a schedule to your deployment\n",
    "[In the UI](http://127.0.0.1:4200), take a look at the `Deployments` tab. Click on your new deployment (called `ML Flow Deployment`). Add a schedule by clicking \"Add\" and choosing your desired frequency.\n",
    "\n",
    "<img src=\"img/adding-a-schedule.png\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ebc6ea",
   "metadata": {},
   "source": [
    "## Execute flow runs from this deployment \n",
    "Starting a local agent will enable you to run execute the code you created in the last step, as frequently as you specified in your schedule. To do this, you simply need to:\n",
    "1. Copy this command: `prefect agent start -q default`.\n",
    "2. Paste in a new terminal window: Visit the `Jupyter Home Page` tab that is already open in your browser. Click \"New\" in the right-hand corner and choose \"Terminal\". Paste the command you copied and hit Enter. In the terminal, you should see that the agent picks up the flow run that you just created :)\n",
    "3. Now when you look at the UI, in the Flow Runs tab you'll see the all of your scheduled flow runs for this deployment, and with the agent running, each flow will move from a `Scheduled` to `Completed` state as the execution time occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca6528a",
   "metadata": {},
   "source": [
    "## Have some fun\n",
    "Experiment on your own in the UI by adding a description to your deployment, parameters, and much more!\n",
    "\n",
    "While in this demo, we use a static dataset (titanic.csv), it's easy to see how the `create_data()` task within `prefect_ml.py` could be altered to draw from any number of sources, using the `requests` library, for instance, to request data from an API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcd7cc7",
   "metadata": {},
   "source": [
    "## Viewing or removing metadata\n",
    "You can view metadata about your flows and deployments by cd-ing into your orion.db: `open ~/.prefect/orion.db`. This will open a SQLite browser if one exists.\n",
    "\n",
    "Alternatively, you can `rm -rf ~/.prefect/orion.db` if you would like to remove all of your existing flows, flow runs, and deployments that you created. If you only want to remove one flow, flow run, or deployment, I would recommend doing so through the UI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a268c5",
   "metadata": {},
   "source": [
    "## Happy engineering!\n",
    "We hope you were able to learn a little more about how Prefect works. We've barely scratched the surface of what's possible with Prefect. For instance, you can also store repeated configuration with blocks and integrate with other tools easily. Please see our docs to learn even more about the possibilities Prefect can give your workflows:\n",
    "https://docs.prefect.io/\n",
    "\n",
    "Some things we didn't touch on in this tutorial:\n",
    "- Other build commands that can be used during deployment: https://docs.prefect.io/concepts/deployments/#deployment-build-options\n",
    "- Flow Storage: https://docs.prefect.io/concepts/storage/\n",
    "- We can set log levels to 'debug', 'error', 'info', and more: https://docs.prefect.io/concepts/logs/\n",
    "- Specifying infrastructure allows you to deploy your agents and control where your flows are run: https://docs.prefect.io/concepts/infrastructure/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e95219b",
   "metadata": {},
   "source": [
    "<img src=\"img/marvin.png\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd591bd",
   "metadata": {},
   "source": [
    "Prefect's mascot, Marvin, is always cooking up new recipes on how to use Prefect. Stop on by [prefect-recipes](https://github.com/PrefectHQ/prefect-recipes) to see more!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "85c41614c0809ea67edb8f40bd66dd48c88720a96ccce3056986d75eb54b153e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
